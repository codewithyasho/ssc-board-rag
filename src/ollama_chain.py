"""
Simple and modern RAG chain setup using LangChain Classic (Groq + FAISS).
"""

from langchain_ollama import ChatOllama
from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain


def create_rag_chain(vectorstore, prompt):
    print("\nüöÄ Initializing RAG chain...")

    # 1Ô∏è‚É£ Create retriever
    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": 5}
    )

    # 2Ô∏è‚É£ Initialize LLM (Ollama Chat)
    llm = ChatOllama(
        model="deepseek-v3.1:671b-cloud",
        base_url="http://localhost:11434",
        temperature=0.2
    )

    # 3Ô∏è‚É£ Define prompt template

    prompt = prompt

    # 4Ô∏è‚É£ Build RAG chain
    document_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, document_chain)

    print("‚úÖ‚úÖ Ollama RAG chain created successfully! \n" + "=" * 60)

    return rag_chain
